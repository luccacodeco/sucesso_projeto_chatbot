import os
import streamlit as st
import pandas as pd
from agent import agent_executor  # Executor configurado no agent.py

# Fun√ß√£o para carregar os dados dos usu√°rios
@st.cache_data
def load_user_data():
    """
    L√™ o CSV de usu√°rios da pasta ml_model/data uma √∫nica vez e faz cache.
    """
    data_path = 'ml_model/data/usuarios.csv'
    return pd.read_csv(data_path)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="LLM Chatbot de Previs√£o de Projetos",
    page_icon="ü§ñ",
    layout="wide"
)

# CSS custom para deixar a sidebar preta semi-transparente
st.markdown(
    """
    <style>
    [data-testid="stSidebar"] {
        background-color: rgba(0, 0, 0, 0.7);
    }
    </style>
    """,
    unsafe_allow_html=True
)

# T√≠tulo e separador
st.title("Chatbot de Previs√£o de Sucesso de Projetos")
st.markdown("---")

# Monta op√ß√µes de usu√°rios para selecionar na sidebar
users_df = load_user_data()
user_options = {
    f"{row['nome']} ({row['cargo']})": row for _, row in users_df.iterrows()
}

# Combobox de sele√ß√£o de usu√°rio
selected_user = st.sidebar.selectbox(
    "Selecione o usu√°rio:",
    list(user_options.keys())
)

# Dados do usu√°rio selecionado
user_info = user_options[selected_user]

# Exibe contexto do usu√°rio na sidebar
st.sidebar.success(f"Nome: {user_info['nome']}")
st.sidebar.info(f"Cargo: {user_info['cargo']}")
st.sidebar.info(f"Projetos: {user_info['historico_projetos']}")
st.sidebar.info(f"Taxa de sucesso: {user_info['sucesso_medio']:.0%}")

# Garante que a sess√£o tem um hist√≥rico
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Mensagem inicial de boas-vindas
    st.session_state.messages.append({
        "role": "assistant",
        "content": (
            "Ol√°, sou o Chatbot de previs√£o de sucesso de projetos!\n\n"
            "Minhas funcionalidades incluem:\n"
            "- Fazer previs√£o de sucesso de um projeto com base em suas informa√ß√µes\n"
            "- Buscar o hist√≥rico dos projetos dos usu√°rios\n\n"
            "Como posso te ajudar?"
        )
    })

# Exibe todo o hist√≥rico acumulado
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Campo de entrada do usu√°rio
prompt = st.chat_input("Digite sua pergunta...")

if prompt:
    # Adiciona pergunta ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # Monta contexto do usu√°rio para passar ao AgentExecutor
    contexto_usuario = (
        f"O usu√°rio √© {user_info['nome']}, cargo {user_info['cargo']}, "
        f"com taxa de sucesso m√©dia de {user_info['sucesso_medio']:.0%}."
    )

    # Junta contexto + pergunta
    prompt_com_contexto = f"{contexto_usuario}\n\n{prompt}"

    # Executa o Agent com o input e mostra a resposta
    with st.chat_message("assistant"):
        resposta = agent_executor.invoke({
            "input": prompt_com_contexto
        })
        output = resposta["output"]
        st.markdown(output)

        # Guarda resposta no hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": output})
